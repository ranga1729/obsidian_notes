- Used to speed up record retrieval in response to specific search criteria.
- Index structures are extra files on disk provides secondary access pathways.
- Index is created based on the **Indexing Field**.
- Any filed can be used to create an index, same file can have several indexes on separate fields or indexes on multiple fields at the same time. 

Types of indexes, 
1. Single Level Ordered Indexes
	- Primary index
	- Secondary index
	- Clustering index
2. Multi Level Tree Structured Index
	- B Tree
	- B+ Tree
3. Hash Index
4. Logical Index
5. Multi Key Index
6. Bitmap Index

### Single Level Ordered Index
- Organize and store the records of a table in a specific order based on one single column.(Indexing column)
- This indexes keeps entries sorted, typically in ascending or descending order. 
- Types,
	1. Primary
	2. Clustering
	3. Secondary
*****
#### 1. Primary Index
- Created automatically when a table is created and a primary key is defined.
- Defined for an ordered file using an **Ordering Key Field** and ordering has been done physically.
- Ordering key has unique values for each record. (ex: Primary key)
- If the ordering key is not unique, clustering index is applied when multiple records in the file have same value for the ordering field. 
	In this scenario, data file is referred as 'Clustered file'. 
	This scenario, it's not a primary index, it's a clustering index.
- A file can have ==only one physical ordering filed.==
	Therefore, a file can have one primary index or one clustering index. 
	I can not hold both primary and clustering index at once. 
![[Pasted image 20250128173640.png]]
- **Primary Index File** : A file with two fields and limited length generates when a primary index is created. 
	Two fields are, 
	1. Ordering Key field : Has the same data as the primary key column in the data file(table). (Ordered)
	2. A pointer to the disk block which contains relevant primary key field.
	Therefore, Index file contains one **index entry**(index record) for each block in the data file. 
Ex: Assume the "name" is the unique field and the name has been used to order the data file. We can create the primary index file as follows.
`K(i)` : Ordering key field, `P(i)` : Pointer to the data block
```
<k(1) = (Aron, Ed), P(1) = address_of_block_1>
<k(2) = (Adams, John), P(2) = address_of_block_2>
<k(3) = (Alexander, Ed), P(3) = address_of_block_3>

//K(i) values are in ordered manner in the Primary index file. But those records are scattered around the table in the data file.
```
![[Pasted image 20250128175528.png]]
- Considering the above table,
$\text{Number of Index Entries in the index file = Number of disk blocks in the data file}$
	Number of index entries in the index file not equal to the number of records in the data file. 
	Because one data block can include several data records.

- **Anchor Record/Block Anchor** : The first record in each data block of the data file.
	Each block has an anchor record. 
- One data block can have multiple records. 
- Pointers of the Primary index file points to the anchor record of the each block. (See the above image)

- **Dense Index** : Indexes that contains index entries for each **record** in the data file. 
- **Sparse Index** : Indexes that contains index entries for several records in the data file. (Because one data block can have multiple records)

- Therefore, Primary indexes falls into the sparse(non-dense) index type.
	Primary index keeps entries for anchor records for each block.

- Primary Index File takes smaller space due to,
	1. Number of index entries < number of records in the data file.
	2. Index entries only hold two fields.
- Therefore, Binary search algorithm causes less block accesses on an index file when compared to the binary search performed on a data file. 

The process of retrieving a record suing a primary index,
1. Perform binary search on the index file(Primary index file) to locate the particular key value we are looking for.
	Since the primary index is sorted, we can perform a binary search. 
	If the index file is spread across b number of blocks, the number of block accesses required for the search operation is $\log_{2}b$ 
	
	Suppose the index record with primary K is stored in **block P(i)**.
Index record is look like this,
	This satisfies the condition,
	$K(i) \leq K \lt K(i+1)$ 
	This means K lies between two index values, so it must be inside **block $i$**
	![[Pasted image 20250128202948.png]]
	All records of K(i) resides in the $i^{th}$ block.
2. Retrieve the Record
	Once we find the index entry, it provides the block address P(i).
	The system fetches the block P(i) from disk and retrieves the required record. 

Ex: 1. Non-indexed ordered file
Let's say we have an ordered file with its key fields. File records are fixed size and are unspanned.
Following details are given and we are going to calculate the block accesses require when performing a binary search.
	number of records(r) = 300,000
	block size(B) = 4096 bytes
	record length(R) = 100 bytes

Calculate the blocking factor(bfr)
	bfr = (B/R) = floor(4096/100) = 40 records block
Number of block needed to store all records
	b = (r/bfr) = ceiling(300,000/40) = 7,500 blocks
Block accesses required
	= $\lceil{log_{2}~b}\rceil$
	= $\lceil{log_{2}~7500}\rceil$
	= 13
Maximum 13 block accesses required to locate a particular record in the data file without using the index.

Ex: 2. For previous scenario given, if we have a primary index file with 9 bytes long ordering key field(V) and 6 bytes long block pointer (P), the required block accesses can be calculated as follows.
number of records(r) = 300,000
	block size(B) = 4096 bytes
	Index entry length($R_i$) = (V+P) = (9+6) = 15 bytes

Calculate the blocking factor for index records
	bfr = (B/R) = 4096/15 = 273 index records per block
Number of index entries required = Number of blocks required for data file.
Therefore, Number of index entries required to store the index file = 7500
Number of blocks needed for the index file,
	$b_i$ = (r/bfr) = ceiling(7500/273) = 28 blocks
Block accesses required
	= $\lceil{log_{2}~b_i}\rceil$
	= $\lceil{log_{2}~28}\rceil$
	= 5
To access the final record using the index, we have to access the data block points by the pointer in the index record we located using the binary search.
Total number of block accesses = $\lceil{log_{2}~b_i}\rceil$ + 1 = 6 block accesses

Problem with primary indexes, 
When adding a new record or deleting an existing record, existing records in the data file might subject to change their index.
Sometimes this change result in change of anchor records as well.
	An unordered overflow file can be used to scale down this problem.
	Adding a linked list of overflow records for each block in the data file is another way to address this issue. 
	Deletion markers can be used to manage the issues with record deletions.
*****
#### 2. Clustering Index
- **Clustered files** : A datafile ordered using a non-key field which does not consist of unique values. 
- **Clustering field** : The filed which is used to order the filed.
- Difference between primary index and clustering index is, primary index consist of distinct values while clustering index does not. 
- Clustering index also consist of two field, 
	1. Clustering field
	2. Block pointer
- In the index file, there's only one entry for distinct values in the clustering field with a pointer to the block where the first record corresponding to the clustering field appear. 
![[Pasted image 20250128231550.png]]
- Clustering key 2 first appears in the 1st block. Therefore, Index file's block pointer corresponds to the clustering key 2 points to the 1st block.

- Clustering index falls into **Sparse index** type since the index file contains entries for distinct values of the ordering key from the data file, rather than having index entries for each and every record in the data file.

Problems with clustering key,
- Since the data file is  ordered, entering and deleting records still causes problems in the clustering index as well they do in the primary index. 
- Common solution : Assign an entire block(or a set of neighbouring blocks) for each value in the clustering field. 
- All records that have similar clustering field will be stored in that allocated block. 
- This issue can be scaled down using an unordered overflow file.  
	Adding a linked list of overflow records for each block in the data file.
- Deletion markers can be used to handle deleting issue. 
![[Pasted image 20250128232710.png]]

Ex: 1. For the same ordered file with r = 300,000, B = 4,096 bytes, let’s say we have used a field “Zip code“ which is non key field, to order the data file.
Assumption: Each Zip Code has equal number of records and there are 1000 distinct values for Zip Codes ($r_i$). Index entries consist of 5-byte long Zip Code and 6-byte long block pointer.

Size of the index record($R_i$) = 5+6 = 11 bytes
Blocking factor($bfr_i$) = $\frac{B}{R_i}$ = floor(4096/11) = 372 index entries per block
Number of block needed to store the index($b_i$) = ceiling(1000/372) = 3 blocks
Blocks access to perform a binary search = $\lceil{log_{2}~b_i}\rceil$ = $\lceil{log_{2}~3}\rceil$ = 2
*****
#### 3. Secondary Index
![[Pasted image 20250129225342.png]]
- Secondary index provide an additional medium for accessing data file which already has a primary index.
- Secondary index file also ordered as primary index, but the data file is not ordered in the same way as the secondary index file is ordered.
- Secondary indexing filed can be, 
	a candidate key(minimal set of attributes that uniquely identifies each tuple within a table),
	non-key value

- Secondary index file has two fields,
	1. non-ordering indexing field
	2. block pointer/record pointer

- For a single data file, few secondary indexes can be exist. 
	Each of them serves as an additional method of accessing the data file. 
- Secondary indexes created on a candidate key has unique values for every record in the file. 
	Therefore, secondary index will get entries for every record in the data file. 
	In this scenario, secondary index creates a dense index which hold index entries for each data file record.

- Index entries are look like,
	`<K(i), P(i)>`
- Binary search can be performed on the secondary index file as the index entries are ordered on the `K(i)` value.
- Block anchors are useless in the secondary index as the data file is ordered physically ordered by the secondary key field. 
	This is the reason to have index entries for each record of data instead using block anchors.

- Since this is a dense index, it requires much storage than primary index. 
- Importance of having a secondary index is we have to do linear search, if there's no a secondary index.
	For a primary index, binary search can be performed on the main data file event if the index is not present, because it's physically sorted.

- Secondary index creates a **logical ordering** of the records using the index.

Ex: If we take the same example in primary index and assume we search for a non-ordering key field V = 9 bytes long, in a file with 300,000 records with a fixed length of 100 bytes. And given block size B =4,096 bytes.

1. **If the secondary index doesn't exist**
Blocking factor(bfr) of data records = (B/R) = floor(4096/100) = 40 records per block
Number of block needed to store the data file = ceiling(300,000/40) = 7,500 blocks
If we perform linear search on this file,
Number of block access required = b/2 = 7500/2 = 3750 block accesses

2. **If we have a secondary indexing on that non-ordering key field with entries for the block pointers P=6 bytes long,**
Length of the index entry($R_i$) =  V+P = 9+6 = 15 bytes
Blocking factor for index records($bfr_i$) = B/$R_i$ = floor(4096/15) = 273

Secondary index is a dense index. 
$\therefore$ Number of index entries = Number of records = 300,000
Number of blocks required for secondary index ($b_i$) = ${r_i}$ / ${bfr_i}$ = ceiling(300,000/273) = 1099

If we perform a binary search on the secondary index,
Number of block accesses required = $\log_2 b_i$ = ceiling($log_2 1099$) = 11 block accesses
Since the data block access also required to get the record,
Total block accesses required = 11+1 = 12 block accesses

*****
### Multilevel Indexes
Multi-level indexing is used to speed up the search process in large databases by reducing the number of disk accesses required to locate a record. It works by creating a hierarchy of indexes, where each level of the index points to the next lower level, ultimately leading to the actual data blocks.
![[Pasted image 20250130082744.png]]
- **First Level Index** : Original index created for the data file.
- **Second Level Index** : Index created for the first-level index
	The second-level index is meant to summarize or point to multiple blocks of the first-level index.

- A multilevel index can be created for any type of first level index(primary, secondary, clustering) as long as the first-level index consist of more than one disk block.
> [!NOTE] Why first-level index required to be consist of more than one disk block ?
>  If the first-level index fits entirely within a single disk block, there is no need for a second-level index because the entire index can be searched with just one disk access. In this case, adding a second-level index would not provide any performance benefit and would instead add unnecessary complexity.
>  The second-level index is meant to summarize or point to multiple blocks of the first-level index, which is only possible if the first-level index spans multiple blocks.

- Multilevel indexing is used to faster the binary search by reducing the search space if the blocking factor of the index is greater than 2.  
> [!NOTE] Why the Blocking Factor Must Be Greater Than 2
> If the blocking factor is 1 or 2, the number of index entries per block is very low. This would result in a large number of blocks being required to store the index, which would negate the purpose of multi-level indexing. A higher blocking factor (greater than 2) ensures that each block contains a sufficient number of index entries, reducing the number of blocks needed and making the index more efficient.
> A higher blocking factor means that each block in the second-level index can point to multiple blocks in the first-level index. This reduces the number of disk accesses required to traverse the index hierarchy. If the blocking factor were 2 or less, the second-level index would not significantly reduce the number of disk accesses, making the multi-level index less effective.

Ex: 
Suppose you have a first-level index that spans 100 blocks, and each block can hold 10 index entries (blocking factor of 10, pointer directs to the anchor record of each block). 
- A second-level index could summarize these 100 blocks into 10 blocks (each pointing to 10 first-level blocks). This reduces the number of disk accesses needed to search the index from 100 to 10 (second-level) + 1 (first-level) = 11 accesses.
- If the blocking factor were 2, the second-level index would need 50 blocks to summarize the 100 first-level blocks, reducing the disk accesses to 50 (second-level) + 1 (first-level) = 51 accesses, which is less efficient.

******
- **Fan-Out($fo$)** : Name of the ==blocking factor of the indexes== ($bfr_i$) in multilevel indexes.
> [!NOTE] In multilevel indexes
> $\text{Number of block accesses required(approximately) = } \log_{fo}~b_i$

- If the first level index has $r_1$ entries, 
	blocking factor for the first level($fo$) = $bfr_1$ = $\left\lfloor \frac{Block~Size}{Record~Size} \right\rfloor$

- Number of blocks required for the first level = $r_1 /fo$

$\therefore$ The number of records in the second level index($r_2$) = ($r_1 /fo$) 
Similarly, $r_3$ = ($r_2 /fo$) 
### Adding another level of indexes
==**The number of levels in the index is determined based on the number of entries in the first level and the blocking factor.**==
If the current level of index requires more than one block to store it's index records, we can add another level of index. 
	Multi-level indexing relies on a hierarchy where each level summarizes the blocks of the level below it. If a level fits within a single block, there is no need for further summarization.
	![[Pasted image 20250130101220.png]]
	The outer blocks are divided into inner blocks which in turn are pointed to the data blocks.
We can keep adding new levels of indexes until the current level of index fits into a single block.

The top level(the last level) of the index is determined by the logarithm of the number of first-level entries respect to the blocking factor.

Number of levels needed to reduce the search space efficiently = $\left\lceil \log_{fo}~(r_1) \right\rceil$

*****
### Indexes on Multiple Keys
- Used if a certain combi9nation of attributes is used frequently.

Ex: we have a file for students, containing 
	`student_id`, 
	`name`, 
	`age`, 
	`gpa`, 
	`department_id`, 
	`department_name`
If we frequently want to find students based on the `department_id` and the `gpa`(ex: `department_id` = 1 and `gpa` = 3.5) we can have the below strategies,
1. Create an index on `department_id`. Access the records with `department_id=1` and then find the records that has 3.5 `gpa`
2. Create an index on `gpa`. Access the records with `gpa=3.5` and then find the records that has `department_id = 1`
3. Both `department_id` and `gpa` have separate indexes. we can get the records that meets the given individual condition (`depadrmrnt_id` = 1 and `gpa` = 3.5 ) and then take the intersection of those records.
the number of individual records which meet one of the specified conditions (either `department_id`= 1 or `gpa`= 3.5) are larger than the records that satisfy both conditions (`department_id`= 1 and `gpa`= 3.5).
$\therefore$ All of these approaches are usable but inefficient.

Most efficient solution: Multiple key index on `departmnent_id` and `gpa` 
- **Composite keys** : A key containing multiple attributes.

#### Ordered Index on Multiple Attributes
- Ordered index entries look like, 
	`<SearchkKey, Pointer>`
- In multiple attributes index, this search key is also a pair of values.
	`searchKey = <attreibute1, attribute2>`
	Ex: `<department_id, gpa>`
	Index entry : `<<department_id, gpa>, Pointer>`
- A lexicographic(alphabetical) ordering of the search key tuple creates an order on this composite search key.
	First all entries are ordered on `deparetment_id`.
	When the `department_id` is the same, these similar records will be sorted on the `gpa`.

##### Partitioned Hashing
- An extension of external hashing. 
> [!NOTE] External Hashing
> ![[External_hashing_divide_stage.webp]]
> **Buckets/Pages** : Data is divided into fixed size buckets(or pages), and each bucket hold records with the similar hash values. The hash function maps keys to specific buckets.

With multiple keys indexes, we take a new approach to create bucket addresses. 
For a key consist of n attributes, n separate hash addresses are generated., The final bucket address is the concatenation of these n addresses. 

Ex: Consider the composite search key is `<department_id, gpa>`
If the `
	`department_id` hashed into a 6-bit address and 
	`gpa` hashed into a 2-bit address
	Then the final bucket address should be 8-bits.
`department_id = 1` hashed to `01`
`gpa = 3.5` hashed to `100011`
Then the bucket address = `01100011`

If we search for students with 3.5 `gpa`, available buckets,
	00`100011`
	01`100011`
	10`100011`
	11`100011`

- Advantages of partitioned hashing,
	1. Ease of extending for any number of attributes.
	2. No need to maintain a separate access structure for individual attributes.
	3. Ability to design the bucket addresses in a way that frequently accessed attributes get higher-order(the left most) bits in the address.
- Disadvantages,
	1. Inability to handle range queries on any of the component attributes.(work only for hashed attributes)
	2. Most of the time, records are not maintained by the order of the key which was used for the hash function. 
		Therefore, using lexicographic order of combination of attributes as a key (eg: ) to access the records would not be straightforward or efficient

##### Grid Files
- Constructed using a grid array with one linear scale for each of the search attributes.
Ex: construct a linear scale for `department_id` and another for `gpa`
![[Pasted image 20250130115045.png]]
- In the grid file, each cell points to some bucket address where the records corresponding 8to that cell are stored. 
Ex: 
1. `departmnent_id=1` and `gpa=3.5` maps to cell (1,3)
	Records for this combination can be found in the corresponding bucket.
	![[Pasted image 20250130145256.png]]
2. `departmnent_id<2` and `gpa>2` 
	![[Pasted image 20250130145506.png]]

- Grid files can be applied to any number of search keys.
	n number of search keys creates a array of n dimensions.

- Advantages,
	1. Possible to partition the file along the dimensions of the search key attributes.
	2. Grid files provide an access by combinations of values along dimensions of grid array.
- Disadvantages,
	1. Space overhead and additional maintenance cost
****
### Other types of Indexes
#### 1. Hash Index
![[Pasted image 20250130152456.png]]
- A secondary structure that allows access to the file using hashing. 
- The search key is defined on an attribute other than the one used for organizing the primary data file.
- Index entries consist of,
	1. Hashed key
	2. pointer to the record
	`<hashed_key, record_pointer>`

#### 2. Bitmap Index
A bitmap index is a type of database index that uses bitmaps (binary numbers, 0s and 1s) to represent the presence or absence of values in a database column. It's especially useful for columns with a limited number of distinct values, such as "gender" (male/female) or "status" (active/inactive), because it allows for efficient querying by using bitwise operations.
- Commonly used for querying on multiple keys. 
- Used for relations which are consist of large number of rows.

Ex: If you have a "status" column with values "active" and "inactive", two bitmaps might be created:
	Bitmap for "active": 1 0 0 1 0 0 (active at rows 1, 4)
	Bitmap for "inactive": 0 1 1 0 1 1 (inactive at rows 2, 3, 5, 6)

Ex: Consider we are creating a bitmap index on column C, for a particular value V and we have n number of records. 
- Therefore, the index contains n number of bits. 
- For a given record with record number `i`, if that record has the value V in column C, the `i-th` bit will be given 1, otherwise it will be 0.
Ex: 
![[Pasted image 20250130160922.png]]
- If we consider value F in column gender, 1st, 3rd, 4th and 7th bits are marked as “1” because record ids of 1,3,4, and 7 have value F in it. But the record ids of 0,2,5 and 6 set to “0”.
- Bitmap index is created on a set of records which are numbered from 0 to n with a record id or row id that can be mapped to a physical address. 
	This physical address is created with block number and record offset within the block.
#### 3. Function based Indexing
- introduced by commercial DBMS products.(Ex: Oracle Relation DBMS)
- A function is applied on one or  more columns and the resulting value is the key to the index.
Ex: Create an index on uppercase of the `last_name` field
```mysql
CREATE INDEX upper_lname
ON Empoloyee(UPPER(Lname));
```
If we execute a query with the `last_name` column, it will use the index rather than searching the entire table. 
```mysql
SELECT Emp_id, Lname
FROM Employee
WHERE UPPER(last_name) = 'SANDUN'
```

*****
#### Index creation
- General way of creating an index in RDBMS,
```mysql
CREATE [UNIQUE] INDEX <index__name>
ON <table__name> (<column__name>[<order>]{,<column__name>[<order>]})
[CLUSTER]
```
- Square bracket `[]` keywords are optional. 
- `[Cluster]` : Sort records in the data file based on the indexing attribute values.
- `<order>` : ASC/DESC (default - ASC)

#### Database Tuning
- Reason to tune indexes,
	1. Long run time of the queries due to deficiency of an index. 
	2. Index may not get utilized. 
	3. Indexing attribute faced frequent changes.
- **Query Plan** : An tool in the DBMS provides detailed information about how the database engine plans to execute a SQL query. Including,
	Execution order of operations(ex: joins, selects, filters)
	Indexes used during query execution
	Number of disk accesses for I/O operations required
	Join methods(ex: nested loops, hash joins)
	Cost estimates for different parts of the query
- By reviewing the query plan, we can identify inefficiencies such as,
	missing or unused indexes
	slow queries
	redundant operations

- Database tuning may include,
	- Change the organization of the index and files. 
	- change non-clustered indexes into clustered indexes or vise versa
	- creating or dropping indexes
	- Rebuild indexes

*****
### Physical Database Design in RDB
- Having an idea about intended use of the databases and queries that will be used, is essential for the database design. 
- Physical design of a DB should provide,
	1. Appropriate structure to store data
	2. Provide better performance
- Factors that DB designers should consider,
	1. Queries
	2. Transactions
	3. Application 

- Considerations for retrieval queries,
	1. Relations that will be accessed by the query
	2. Attributes specified for the selection condition
	3. Type of conditions(equal, unequal, range)
	4. Attributes help in linking tables(join conditions)
	5. Attributes retrieved by the query
- "Attributes specified for the selection condition" and "Attributes help in linking tables(join conditions)" are candidates for indexes.

- Considerations for update operations,
	1. File subjects to update
	2. Type of update(insert, delete, update queries)
	3. Which attributes are specified in the selection condition, to update or delete.
	4. Attributes whose values are subject to change by the update query.
- "Which attributes are specified in the selection condition, to update or delete" are useful for index creations.

- Whether to set up a clustered index,
	We cannot have both primary and clustering index on the same file because the data file is physically ordered accordingly in both scenarios.
	We can apply clustered index, if it supports answer the queries just by accessing index.
	Otherwise, there is no use of making a clustered index. If multiple queries require clustering on different attributes, we should evaluate the gain of each and decide on which attribute to use.
- Whether to use a dynamic hashing for the file
	suitable for files which are subject to frequent expansion and shrinking.