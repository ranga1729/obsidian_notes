Deep learning is a subset of machine learning that uses neural networks with many layers to model complex patterns in data. 
It is inspired by the structure and function of the human brain with algorithms designed to mimic the way neurons in the brain communicate with each other.
Deep learning is useful when handling large amounts of unstructured data such as images, audio and texts.
#### What's a Neural Network ?
**Neural Networks** are the core components of deep learning. They are computational models that consist of layers of interconnected nodes, or neurons, which are organized in three types of layers: input layer, hidden layers, and output layer.
![[Pasted image 20241202093351.png]]
![[Pasted image 20241202093325.png]]

#### Key components of a Neural network,
1. **Neuron**
Basic unit of a neural network that receives input, process it and pass the output to the next layer. Each neuron applies a weighted sum to the inputs and then passes the result through an activation function.
	![[Pasted image 20241202093709.png]]

2. **Layers**
Three main layers, 
	1. Input layer: Receives the initial data.
	2. Hidden layer: Perform computations and feature extraction. A network can have one or many hidden layers.
	3. Output layer: Produces the final prediction or classification.

3. **Weights and Biases**
Parameters that are adjusted during training to minimize the error in predictions. 
- Weights: Determine the strength of the connection between neurons 
- Biases: Allow the activation function to be shifted

4. **Activation Functions**
Functions applied to the output of each neuron to introduce non-linearity into the model, enabling it to learn complex patterns. 
Common activation functions include,
	ReLU (Rectified Linear Unit), 
	Sigmoid, 
	Tanh

5. **Loss Function**
Measures how well the model's predictions match the actual data.
Common loss functions include,
	Mean Squared Error for regression tasks 
	Cross-Entropy Loss for classification tasks

6. **Backpropagation**
The process of updating the weights and biases through the network to minimize the loss function. This is done using gradient descent or other optimization algorithms.

****
#### Types of Neural Networks,
1. **Feedforward Neural Networks (FNNs)**
	The simplest type, where connections between the nodes do not form a cycle. Used for tasks like image recognition and simple prediction problems.
2. **Convolutional Neural Networks (CNNs)** 
	Specialized for processing data with grid-like topology, such as images. They use convolutional layers to automatically and adaptively learn spatial hierarchies of features from input images.
3. **Recurrent Neural Networks (RNNs)** 
	Designed for sequential data. They have connections that form directed cycles, allowing information to persist. Used in applications like language modeling and time series prediction.
4. **Long Short-Term Memory Networks (LSTMs)** 
	A type of RNN designed to handle long-term dependencies and solve the vanishing gradient problem. Widely used in tasks like speech recognition and text generation.
5. **Generative Adversarial Networks (GANs)** 
	Consist of two neural networks, a generator and a discriminator, that compete against each other. Used for generating realistic data samples, such as synthetic images.
6. **Autoencoders** 
	Used for unsupervised learning tasks like dimensionality reduction and anomaly detection. They learn to compress data into a lower-dimensional representation and then reconstruct it.