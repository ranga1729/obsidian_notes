There may be more than one solutions to the same problem or may be more than one implementation of the same function.
 
 How do we know what's best solution ?

"Big O" is a system/way of generalizing code and talking about it and comparing code and its performance to other pieces of code.

**Benefits of using Big O notations,**
- It's important to have precise vocabulary to talk about how our code performs.
- Useful for discussing trade-offs between different approaches. 
- When your code slows down or crashes, identifying parts of the code that are inefficient can help us find pain points in our applications.

Ex:
A function that calculates the sum of all numbers from 1 to some number n.

Solution 1
```js
function addUpTo(n){
	let total = 0;
	for(let i = 1; i <= n; i++){
		total += i;
	}
	return total;
}
```

Solution 2
![[Pasted image 20240106035623.png]]
```js
function addUpTo(n){
	return n * (n + 1) / 2;
}
```

What's the better solution ?

What does better mean ?
	1. Faster ?
	2. Less memory-intensive ?
	3. More readable ?

How to use timers in JavaScript ?
```js
function addUpTo(n){
	let total = 0;
	for(let i = 1; i <= n; i++){
		total += i;
	}
	return total;
}

let t1 = performance.now();
addUpTo(10000000000);
let t2 = performance.now();
console.log('Time elapsed: ${(t2-t1) / 1000} seconds.');
```
Ex:
Solution 1
![[Pasted image 20240106040719.png]]
Solution 2
![[Pasted image 20240106041022.png]]
Manually timing the program isn't reliable when we want to measure the efficiency of a code. 

#### The problem with time,
- Different machines will record different times.
- The same machine will records different times.
- For fast algorithms, speed measurements may not be precise enough.

#### If not time, then what ?
Rather than counting seconds, let's count the number of simple operations the algorithm has to perform. 

Ex: 
Solution 2
![[Pasted image 20240106123806.png]]
In the 2nd solution, there are only 3 calculations. 
It doesn't matter whether the 'n' is 1000 or 1 billion or...it just takes only 3 calculations/operations.

Solution 2
![[Pasted image 20240106165901.png]]
Depending on what we count, the number of operations can be low as 2n or as high as 5n+2 operations.
If n=10, then 52 operations. 

But it doesn't matter. Because we don't want to count the number of operations here, we want to focus on the bigger picture/general trend here. 
**Regardless of the exact number, the number of operations grows roughly proportionally with n.**


### What is Big O ?
Big O is a way to formalize fuzzy counting. It allows us to talk formally about how the runtime of an algorithm grows as the inputs grow. (the relationship between input size and then the time relative) 
With Big O, we don't care about the details, only the trends.

**Definition of Big O,**
We say that algorithm is **O(f(n))** if the number of simple operations the computer has to do is eventually less than a constant times **f(n)**, as **n** increases.
- f(n) could be linear (f(n) = n)
		As the n(input) scales, the runtime scales as well. 
- f(n) could be quadratic (f(n) = n<sup>2</sup>)
		As n grows, the runtime grows as square.
- f(n) could be constant (f(n) = 1)
		As n grows, it doesn't have any impact. Runtime is always constant. 
- f(n) could be something entirely different.

**When we talk about the Big O, we always talk about the worst case scenario/upper bound.**

Ex: 
```js
function addUpTo(n){
	return n * (n + 1) / 2;
}
```
Solution 2 takes always 3 operations. No matter how n grows, the runtime is a constant.
	**O(1)**

```js
function addUpTo(n){
	let total = 0;
	for(let i = 1; i <= n; i++){
		total += i;
	}
	return total;
}
```
As n grows, the number of operations grows as well. 
Because the number of operations is bounded by a multiple of n.(Ex: 10n or 5n)
	**O(n)**

It doesn't matter whether it's 10n, 5n or 6n. Because we simplify it to 'n'. Basically we are concerned with just the order of magnitude.
Ex:
![[Pasted image 20240106201304.png]]
First part is **O(n)** and the second part is **O(n)** too.
Total would be **2n**. But we don't care about that. We care about the bigger picture. As n grows, number of operations grows. So we simplify it to **O(n)**.

Ex:
![[Pasted image 20240106205137.png]]
As n grows, number of operations grows in both loops. Since one loop is nested in the other loop, it's **O(n * n) = O(n<sup>2</sup>)**
This means as n grows, the overall runtime roughly grows at the rate of **n<sup>2</sup>**

### Simplifying Big O Expression
When determining the time complexity of an algorithm, there are some helpful rule of thumbs for big O expression. These rules of thumbs are consequences of the definition of big O notation.

1. Constant doesn't matter.
	We only care about the broadest fuzzy big picture view.
	O(2n)  ->  O(n)
	O(500)  ->  O(1)
	O(13n<sup>2</sup>)   ->  O(n<sup>2</sup>) 
2. Smaller terms doesn't matter.
	O(n  + 10)  ->  O(n)
	O(1000n  + 50)  ->  O(n)
	O(n<sup>2</sup> + 5n + 8)  ->  O(n<sup>2</sup>)

#### Big O Short-hands
Keep in mind,
- Analyzing complexity with Big O can get complicated.
- There are several rules of thumbs that can help
- These rules won't always work, but are a helpful starting point.
	1. Arithmetic operations are constants.
		Adding, subtracting, dividing they all gonna take the same amount of time. 
		If you do 2+2 or 2million+4million, they both gonna take the same amount o time. It doesn't really matter the size of the number.
	2. Variable assignment is constant
		x = 1000 and x = 20,000 both assignments takes roughly the same amount of time.
	3. Accessing elements in an array (by index) or object (by key) is constant
		if array[] is and array, then array[0], array[100],
		if object is and object, then object.name , object.age
		all takes the same amount of time.
	4. In a loop, the complexity is the length of the loop times the complexity of whatever happens inside of the loop.
		If we looping from 0 to n, as n grows, that loop grows.
		And whatever happen inside that loop is also consequential. 
		If we have nested loop, runtime grows exponentially. 

Ex: 
```js
function logAtLeast5(n){
	for (var i = 1; i <= Math.max(5, n); i++){
		console.log(i);
	}
}
```
This program at least print 5 numbers.

What's the Big O here ?
	In Big O notation, we care about what happens as n grows larger. So we don't have to worry about 5. 
	As n grows larger and larger, runtime of this program grows proportionally. 
	So, we can simplify it to **O(n)**

Ex:
```js
function logAtLeast5(n){
	for (var i = 1; i <= Math.min(5, n); i++){
		console.log(i);
	}
}
```
This program choose the minimum number unlike the previous version. 
What's the Big O here ?
	As n grows here, it doesn't matter because we take the min, which if 5. even if n approaches 10, 100, 100 or 1 million, it runs 5 time. 
	We can simplify it to **O(1)**


#### Common Big O notations
![[Pasted image 20240106223006.png]]

### Space Complexity
So far we have been focusing on **time complexity**: how can we analyze the runtime of an algorithm as the size of the inputs increases.

We can also use Big O notation to analyze **space complexity**: how much additional memory do we need to allocate in order to run the code in our algorithm. 

In this part, we are going to ignore the space taken up by inputs and only consider about the space taken up by the algorithm itself. 
	Because as n(inputs) grows, obviously space taken up by n(inputs) grows up.
This is called **Auxiliary space complexity** (space required by the algorithm itself, not including space taken up by the inputs.)

#### Space complexity in JS: Rules of thumb 
- Most primitive (booleans, numbers, undefined, null) are constant space.
- String required O(n) space (Where n is the string length).
	If it grows to 50 character, the string takes up 50 times more space than a single character string.
- Reference types are generally O(n), where n is the length(for arrays) or the number of keys(for objects).
	n is the number of elements in the array or number of keys in the object. 

Ex: 
```js
function sum(arr){
	let total = 0;
	for (let i = 0; i < arr.length; i++){
		total += arr[i];
	}
	return total;
}
```
![[Pasted image 20240113115858.png]]
For space, there's only 2 numbers(variables) in this example. 
No matter what the size of the array(arr) is, this code/algorithm only use 2 variables to count the sum of the array. 
That means we have constant space consumes by this code. 
It's **O(1)** space.

Ex: 
```js
function double(arr){
	let newArr = [];
	for(let i = 0; i < arr.length; i++){
		newArr.push(2 * arr[i]);
	}
	return newArr;
}
```
In this example, the new array 'newArr' is getting longer and longer, directly and proportion to the input array 'arr' grows. 
(If 'arr' has 10 items, 'newArr' is going to have 10 items.)
In addition to that, we have to store the reference of the 'newArr' and 'i' inside the for loop. So it's technically (n+2) items are here to takes up space.
But in general, this algorithm takes **O(n)** space. 

### Logarithms 
Logarithm is the inverse of the exponentiation. 

Ex:
log<sub>2</sub> (8) = 3   --->   2<sup>3</sup> = 8
![[Pasted image 20240113124426.png]]

Commonly we use log<sub>2</sub>, log<sub>10</sub> and log<sub>e</sub> when dealing with logarithms. 
But with Big O notations we focus on the general idea so we use just log<sub>2</sub> as **log** without the base. We just care about the general trend.
log<sub>2</sub> === log

The logarithm of a number roughly measures the number of times you can divide that number by 2 before get a value that's less than or equal to 1. 
Ex: 
	log<sub>2</sub> (8) = 3   --->   2<sup>3</sup> = 8
	8 can be divided by 2, 3 times until it reaches 1. 
	8 / 2 =4
	4 / 2 = 2
	2 / 2 = 1

Ex: 
	25 / 2 = 12
	12.5 / 2 = 6.25
	6.25 / 2 = 3.125
	3.125 / 2 = 1.5625
	1.5625 / 2 = 0.78125
	log (25) =  4.64

#### Logarithm Complexity
![[Pasted image 20240106223006.png]]
As this graph show us, **O(log n)** is greater than having **O(n.log n)** time complexity.
But **O(n.log n)** is better than **O(n<sup>2</sup>)**

Certain searching algorithms have logarithmic time complexity.
Efficient sorting algorithms involve logarithms.
Recursion sometimes involves logarithmic space complexity.
